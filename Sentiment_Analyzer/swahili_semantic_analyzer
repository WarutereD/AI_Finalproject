import pandas as pd
import numpy as np

import spacy
from spacy_langdetect import LanguageDetector


# Load the default English language model and add the language detector to the pipeline
nlp = spacy.load("en_core_web_sm")
nlp.add_pipe(LanguageDetector(), name="language_detector", last=True)

# Define a function to preprocess Swahili text
def preprocess_swahili(text):
    # Process the text with the pipeline
    doc = nlp(text)
    
    # If the detected language is not Swahili, return an empty string
    if doc._.language["language"] != "sw":
        return ""
    
    # Otherwise, return the preprocessed text
    return " ".join([token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha])
    
# Load the Swahili dataset
df = pd.read_csv("Sentiment_Analyzer/dataset/swahili_test.csv")

# Apply the Swahili text preprocessing function
df["maneno"] = df["maneno"].apply(preprocess_swahili)
df = df[df["maneno"] != ""] # Filter out texts that are not in Swahili

# Split dataset into training and testing sets
train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)

# Extract features from text using TfidfVectorizer
vectorizer = TfidfVectorizer(min_df=2, max_df=0.8, sublinear_tf=True, use_idf=True)
train_features = vectorizer.fit_transform(train_data["maneno"])
test_features = vectorizer.transform(test_data["maneno"])

# Train logistic regression model
model = LogisticRegression()
model.fit(train_features, train_data["lugha"])

# Predict sentiment for testing set
y_pred = model.predict(test_features)

# Evaluate model performance
accuracy = accuracy_score(test_data["lugha"], y_pred)
precision = precision_score(test_data["lugha"], y_pred, average="weighted")
recall = recall_score(test_data["lugha"], y_pred, average="weighted")

y_true = test_data["lugha"]
f1 = f1_score(y_true, y_pred, average='weighted')  # or 'macro', 'micro', depending on your needs
print("F1 score:", f1)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
