import pandas as pd
import numpy as np
import nltk
nltk.download("stopwords")
from sklearn.metrics import f1_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score
from nltk.stem.porter import PorterStemmer
from nltk.corpus import stopwords
import re

# Load dataset
df = pd.read_csv("Sentiment_Analyzer/dataset/IMDB Dataset.csv")

# Text preprocessing
stemmer = PorterStemmer()
stop_words = stopwords.words("english")
df["text"] = df["text"].apply(lambda x: " ".join([stemmer.stem(word) for word in re.sub('[^a-zA-Z0-9\s]', '', x).split() if word not in stop_words]))

# Split dataset into training and testing sets
train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)

# Extract features from text using TfidfVectorizer
vectorizer = TfidfVectorizer(min_df=2, max_df=0.8, sublinear_tf=True, use_idf=True)
train_features = vectorizer.fit_transform(train_data["text"])
test_features = vectorizer.transform(test_data["text"])

# Train logistic regression model
model = LogisticRegression()
model.fit(train_features, train_data["sentiment"])

# Predict sentiment for testing set
y_pred = model.predict(test_features)


# Evaluate model performance
accuracy = accuracy_score(test_data["sentiment"], y_pred)
precision = precision_score(test_data["sentiment"], y_pred, average="weighted")
recall = recall_score(test_data["sentiment"], y_pred, average="weighted")

y_true = test_data["sentiment"]
f1 = f1_score(y_true, y_pred, average='weighted')  # or 'macro', 'micro', depending on your needs
print("F1 score:", f1)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
